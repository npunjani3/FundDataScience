{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "apparent-cookbook",
   "metadata": {},
   "source": [
    "# Extra Credit Homework Assignment: \n",
    "# Model Parameter Tuning\n",
    "\n",
    "As in the previous assignments, in this homework assignment you will continue your exploration of the [SWAN-SF Dataset](https://doi.org/10.7910/DVN/EBCFKM), described in the paper found [here](https://doi.org/10.1038/s41597-020-0548-x).\n",
    "\n",
    "This assignment will continue to utilize a copy of the extracted feature dataset we used in Homework 5. Recall that the dataset has been processed by performing log, z-score and range scaling. We continuing to use more than one partition worth of data, so for the scaling, the mean, standard deviation, minimum, and maximum were calculated using data from both partitions so that a global scaling can be performed on each partition. \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-portugal",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the Data\n",
    "\n",
    "This assignment will continue to use [Partition 1](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/BMXYCB) for a training set and [Partition 2](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/TCRPUD) as a testing set. \n",
    "\n",
    "---\n",
    "\n",
    "For this assignment, cleaning, transforming, and normalization of the data has been completed using both partitions to find the various minimum, maximum, standard deviation, and mean values needed to perform these operations. Recall from lecture that we should not perform these operations on each partition individually, but as a whole as there may(will) be different values for these in different partitions. \n",
    "\n",
    "For example, if we perform simple range scaling on each partition individually and we see a range of 0 to 100 in one partition and 0 to 10 in another. After individual scaling the values with 100 in the first would be mapped to 1 just like the values that had 10 in the second. This can cause serious performance problems in your model, so I have made sure that the normalization was treated properly for you. \n",
    "\n",
    "Below you will find the full partitions and `toy` sampled data from each partition, where only 20 samples from each of our 5 classes have been included in the data.  \n",
    "\n",
    "#### Full\n",
    "- [Full Normalized Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/normalized_partition1ExtractedFeatures.csv)\n",
    "- [Full Normalized Partition 2 feature dataset](http://dmlab.cs.gsu.edu/solar/data/normalized_partition2ExtractedFeatures.csv)\n",
    "\n",
    "#### Toy\n",
    "- [Toy Normalized Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/toy_normalized_partition1ExtractedFeatures.csv)\n",
    "- [Toy Normalized Partition 2 feature dataset](http://dmlab.cs.gsu.edu/solar/data/toy_normalized_partition2ExtractedFeatures.csv)\n",
    "\n",
    "Now that you have the two files, you should load each into a Pandas DataFrame using the [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-spare",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "\n",
    "As was done in Homework 5 and 6, for each of the models we evaluate in this assignmnet, you will calculate the True Skill Statistic score using the test data from Partition 2 to determine which model performs the best for classifying the positive flaring class.\n",
    "\n",
    "    True skill statistic (TSS) = TPR + TNR - 1 = TPR - (1-TNR) = TPR - FPR\n",
    "\n",
    "Where:\n",
    "\n",
    "    True positive rate (TPR) = TP/(TP+FN) Also known as recall or sensitivity\n",
    "    True negative rate (TNR) = TN/(TN+FP) Also known as specificity or selectivity\n",
    "    False positive rate (FPR) = FP/(FP+TN) = (1-TNR) Also known as fall-out or false alarm ratio\n",
    "\n",
    "\n",
    "**Recall**\n",
    "\n",
    "    True positive (TP)\n",
    "    True negative (TN)\n",
    "    False positive (FP)\n",
    "    False negative (FN)\n",
    "    \n",
    "See [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) for more information.\n",
    "\n",
    "Below is a function implemented to provide your score for each model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "individual-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pandas import DataFrame \n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tss(y_true, y_predict):\n",
    "    '''\n",
    "    Calculates the true skill score for binary classification based on the output of the confusion\n",
    "    table function\n",
    "    \n",
    "        Parameters:\n",
    "            y_true   : A vector/list of values that represent the true class label of the data being evaluated.\n",
    "            y_predict: A vector/list of values that represent the predicted class label for the data being evaluated.\n",
    "    \n",
    "        Returns:\n",
    "            tss_value (float): A floating point value (-1.0,1.0) indicating the TSS of the input data\n",
    "    '''\n",
    "    scores = confusion_matrix(y_true, y_predict).ravel()\n",
    "    TN, FP, FN, TP = scores\n",
    "    #print('TN={0}\\tFP={1}\\tFN={2}\\tTP={3}'.format(TN, FP, FN, TP))\n",
    "    tp_rate = TP / float(TP + FN) if TP > 0 else 0  \n",
    "    fp_rate = FP / float(FP + TN) if FP > 0 else 0\n",
    "    \n",
    "    return tp_rate - fp_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04d14e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In addition to the TSS, you will be asked to also calculate the Heidke Skill Score (HSS) to see how much better your model performs than a random forecast.  \n",
    "\n",
    "Below is a function implemented to provide your score fore each model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab05f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hss(y_true, y_predict):\n",
    "    '''\n",
    "    Calculates the Heidke Skill Score for binary classification based on the output of the confusion\n",
    "    table function.\n",
    "    \n",
    "    The HSS measures the fractional improvement of the forecast over the standard forecast.\n",
    "    The \"standard forecast\" is usually the number correct by chance or the proportion \n",
    "    correct by chance.\n",
    "    \n",
    "        Parameters:\n",
    "            y_true   : A vector/list of values that represent the true class label of the data being evaluated.\n",
    "            y_predict: A vector/list of values that represent the predicted class label for the data being evaluated.\n",
    "    \n",
    "        Returns:\n",
    "            hss_value (float): A floating point value (-inf,1.0) indicating the HSS of the input data. \n",
    "                Negative values indicate that the chance forecast is better, 0 means no skill, and a perfect forecast obtains a HSS of 1.\n",
    "    '''\n",
    "    scores = confusion_matrix(y_true, y_predict).ravel()\n",
    "    TN, FP, FN, TP = scores\n",
    "    #print('TN={0}\\tFP={1}\\tFN={2}\\tTP={3}'.format(TN, FP, FN, TP))\n",
    "    P = float(TP + FN)\n",
    "    N = float(FP + TN)\n",
    "    numerator = 2*((TP * TN) - (FN * FP))\n",
    "    denominator = P*(FN + TN) + N*(TP + FP)\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-alfred",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As in the previous assignments, we will be utilizing a binary classification of our 5 class dataset. So, below is the helper function to change our class labels from the 5 class target feature to the binary target feature. The function is implemented to take a dataframe (e.g. our `abt`) and prepares it for a binary classification by merging the `X`- and `M`-class samples into one group, and the rest (`NF`, `B`, and `C`) into another group, labeled with `1`s and `0`s, respectively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handled-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomize_X_y(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    dichotomizes the dataset and split it into the features (X) and the labels (y).\n",
    "    \n",
    "    :return: two np.ndarray objects X and y.\n",
    "    \"\"\"\n",
    "    data_dich = data.copy()\n",
    "    data_dich['lab'] = data_dich['lab'].map({'NF': 0, 'B': 0, 'C': 0, 'M': 1, 'X': 1})\n",
    "    y = data_dich['lab']\n",
    "    X = data_dich.drop(['lab'], axis=1)\n",
    "    return X.values, y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-manufacturer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reading the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "viral-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/npunjani/Documents/Fund_Data_Science/data'\n",
    "data_file = \"normalized_partition1ExtractedFeatures.csv\"\n",
    "data_file2 = \"normalized_partition2ExtractedFeatures.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infectious-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "abt = pd.read_csv(os.path.join(data_dir, data_file))\n",
    "abt2 = pd.read_csv(os.path.join(data_dir, data_file2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78989fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run Undersampling and Feature Selection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed4002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_under_sample_clust(data:DataFrame)->DataFrame:\n",
    "    grouped = data.groupby('lab')\n",
    "    min_group = grouped.size().min()\n",
    "    result_list = []\n",
    "    for name, group in grouped:\n",
    "        if group.shape[0] > min_group:\n",
    "            size = min_group\n",
    "            a = [name]*size \n",
    "            df = DataFrame(a, columns=['lab'])\n",
    "            grp_feats_df = group.copy().drop(['lab'], axis=1)\n",
    "            grp_feats = grp_feats_df.values\n",
    "            km = KMeans(n_clusters=size)\n",
    "            km.fit(grp_feats)\n",
    "            clstrs = km.cluster_centers_\n",
    "            df2 = DataFrame(clstrs, columns=grp_feats_df.columns)\n",
    "            df = df.join(df2)\n",
    "            result_list.append(df)\n",
    "        else:\n",
    "            result_list.append(group)\n",
    "    sampled = pd.concat(result_list, axis=0)\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818faa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeat = 20\n",
    "thresh = 0.5\n",
    "\n",
    "abt3 = abt.loc[abt['R_VALUE_median']> thresh ]\n",
    "# Split the target and descriptive features for Partition 1 into two \n",
    "# different DataFrame objects\n",
    "df_labels = abt3['lab'].copy()\n",
    "df_feats = abt3.copy().drop(['lab'], axis=1)\n",
    "\n",
    "# Split the target and descriptive features for Partition 2 inot two\n",
    "# different DataFrame Objects\n",
    "df_test_labels = abt2['lab'].copy()\n",
    "df_test_feats = abt2.copy().drop(['lab'], axis=1)\n",
    "\n",
    "# Do feature selection\n",
    "feats1 = SelectKBest(f_classif, k=numFeat).fit(df_feats, df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041022de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a training dataset from Partition 1 with only the selected descriptive \n",
    "# features and the target feature\n",
    "df_selected_feats1 = df_feats.loc[:, feats1.get_support()]\n",
    "df_train_set1 = pd.concat([df_labels, df_selected_feats1], axis=1)\n",
    "\n",
    "# Construct a testing dataset from Partition 2 with only the selected descriptive\n",
    "# features and the target feature\n",
    "df_test_selected_feats1 = df_test_feats.loc[:, feats1.get_support()]\n",
    "df_test_set1 = pd.concat([df_test_labels, df_test_selected_feats1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f67819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled1 = perform_under_sample_clust(df_train_set1)\n",
    "\n",
    "dicotomized_train = dichotomize_X_y(sampled1)\n",
    "dicotomized_test = dichotomize_X_y(df_test_set1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dab10a",
   "metadata": {},
   "source": [
    "---\n",
    "### Q1 (25 points)\n",
    "\n",
    "Like in Q10 of HW6, this question will be utilizing the filtered and sampled datasets that was constructed above. For this question, you will again train your models on the feature selected data that had the instances below our thrshold filtered out and then had sampling by clustering performed on it. \n",
    "\n",
    "You will again be constructing an [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on each one of the different datasets. Like before, you should set the `class_weight` to `balanced` when you construct your models. You will again evaluate several different settings for the regularization parameter `C`, and kernel coefficient `gamma`. The `kernel` paramter will be constant on `rbf`. \n",
    "\n",
    "For each of the settings, you should train the model on your training data, then test it on the testing data with the same set of selected descriptive features. You will then calculate both the TSS and HSS scores. You should store the results of your experiments for each setting in a DataFrame for later questions.  Each entry of the DataFrame should contain 'C', 'gamma', 'tss', 'hss', 'tp', 'tn', 'fp', 'fn' for each `C` and `gamma` setting you evaluate.\n",
    "\n",
    "**Note:** The testing data has the samples in it that are below our threshold value, so you will first need to filter those out of the data you plan to pass to your model for testing. However, you still want those instances included in the calculation of the TSS and HSSS. So, your groud truth `lab` data should include all the instances in partition 2. You will need to concatenate a vector with all zeros in it to the match the labels you partitioned from the model testing data. \n",
    "\n",
    "Let's give you a representation of that:\n",
    "    \n",
    "    labels_from_data = [labels for samples > threshold] + [labels for samples <= threshold]\n",
    "    predict_labels = [labels from the model on > thrshold samples] + [0s the length of samples <= threshold]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "c_vals = np.arange(0.1, 1, 0.1)\n",
    "gamma_vals = np.arange(0.1, 1, 0.1)\n",
    "temp = [c_vals, gamma_vals]\n",
    "params = list(itertools.product(*temp))\n",
    "cols = ['C', 'gamma', 'tss', 'hss', 'tp', 'tn', 'fp', 'fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9381cc3",
   "metadata": {},
   "source": [
    "---\n",
    "### Q2 (25 points)\n",
    "\n",
    "In this question you will be plotting your `tss` and `hss` scores in a 3D surface plot so you can investigate what ranges of values you might want to look into further. You will use [matplotlib.pyplot.figure](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html) as your plotting canvas. \n",
    "\n",
    "* You should set the `figsize` parameter to some set of values, maybe `(10,10)`.\n",
    "\n",
    "* You should [add_subplot](https://matplotlib.org/3.3.4/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure.add_subplot) of `projection` type `3d` to your figure object to get the axes.\n",
    "\n",
    "* You should set the axes labels using the [set_xlabel](https://matplotlib.org/3.3.4/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel) for the x axis and the correspondig set methods for the remaining y and z axes.\n",
    "\n",
    "* You will then use the [plot_trisurf](https://matplotlib.org/stable/tutorials/toolkits/mplot3d.html#tri-surface-plots) to plot your 3d surface using `C`, `gamma`, and `tss` as your `x`, `y`, and `z` axes in one plot.\n",
    "\n",
    "* Make a second plot with the only change being `hss` instead of `tss`\n",
    "\n",
    "**Note:** I have imported [colormaps](https://matplotlib.org/stable/tutorials/colors/colormaps.html) as `cm` above. You should use this to set the `cmap` parameter of your plots and make them look nice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62610f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_look_at = [\"C\", \"gamma\", \"tss\"]\n",
    "features_to_look_at2 = [\"C\", \"gamma\", \"hss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed097e",
   "metadata": {},
   "source": [
    "---\n",
    "### Q3 (12.5 points)\n",
    "\n",
    "From the plots in Q2 we see that the best performance is in a range where `C` is around 0.1. So, lets repeat the experiments from Q1 but make it a more granular exploration of the range between 0 and 0.1 for `C`. Make sure to save your results to a DataFrame again, we will plot them again in the next question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e91ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "c_vals = np.arange(0.01, 0.1, 0.01)\n",
    "gamma_vals = np.arange(0.1, 1, 0.1)\n",
    "temp = [c_vals, gamma_vals]\n",
    "params = list(itertools.product(*temp))\n",
    "cols = ['C', 'gamma', 'tss', 'hss', 'tp', 'tn', 'fp', 'fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726bb1bf",
   "metadata": {},
   "source": [
    "---\n",
    "### Q4 (12.5 points)\n",
    "\n",
    "Repeat the plotting done in Q2, but using the results from Q3 to see how the `tss` and `hss` change as we zero in on a potential area we want to use for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3c82c",
   "metadata": {},
   "source": [
    "---\n",
    "### Q5(15 points)\n",
    "\n",
    "We seem to have found a good set of values for `C` but `tss` and `hss` seem like they might increase if we investigate further on `gamma` so, do this.  Run the same values of `C` but expand the values of `gamma` to the range and increments below.  Then plot your results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e822f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "c_vals = np.arange(0.01, 0.04, 0.01)\n",
    "gamma_vals = np.arange(0.1, 5, 0.1)\n",
    "temp = [c_vals, gamma_vals]\n",
    "params = list(itertools.product(*temp))\n",
    "cols = ['C', 'gamma', 'tss', 'hss', 'tp', 'tn', 'fp', 'fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfee997",
   "metadata": {},
   "source": [
    "---\n",
    "### Q6(10 points)\n",
    "\n",
    "It looks like we found a reasonable set of values around `gamma` equals 4 to 5 and `C` between 0.01 and 0.03.  Find the `C` and `gamma` in between these ranges from the experiments in Q5  that `jointly` maximise the two values. Meaning their sum is maximized.  Then print out the values of `C` and `Gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------------------------------\n",
    "    # TODO: Complete here.\n",
    "    #----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
